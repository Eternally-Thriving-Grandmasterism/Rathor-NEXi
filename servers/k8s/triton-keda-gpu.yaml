apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: triton-gpu-utilization-scaledobject
  namespace: rathor-inference
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: triton-inference
  minReplicaCount: 1
  maxReplicaCount: 12
  cooldownPeriod: 180
  pollingInterval: 15
  advanced:
    restoreToOriginalReplicaCount: true
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300
          policies:
          - type: Percent
            value: 25
            periodSeconds: 60
        scaleUp:
          stabilizationWindowSeconds: 0
          policies:
          - type: Percent
            value: 100
            periodSeconds: 15
          - type: Pods
            value: 4
            periodSeconds: 15
  triggers:
  # 1. GPU utilization (via prometheus-nvidia-gpu-exporter)
  - type: prometheus
    metadata:
      serverAddress: http://prometheus-server.monitoring.svc.cluster.local
      metricName: nvidia_gpu_utilization
      threshold: "75"  # scale when average GPU util > 75%
      query: |
        avg(rate(nvidia_gpu_utilization{namespace="rathor-inference"}[5m])) by (pod)
  # 2. Inference queue depth (custom metric)
  - type: prometheus
    metadata:
      serverAddress: http://prometheus-server.monitoring.svc.cluster.local
      metricName: triton_queue_depth
      threshold: "15"
      query: sum(rate(triton_queue_depth[5m])) by (pod)
  # 3. Inference latency (custom metric)
  - type: prometheus
    metadata:
      serverAddress: http://prometheus-server.monitoring.svc.cluster.local
      metricName: triton_inference_latency_ms
      threshold: "600"
      query: avg(rate(triton_inference_latency_ms[5m])) by (pod)
  # 4. Valence spike rate (custom metric â€“ proactive scaling on high demand)
  - type: prometheus
    metadata:
      serverAddress: http://prometheus-server.monitoring.svc.cluster.local
      metricName: rathor_valence_spikes_per_minute
      threshold: "120"
      query: sum(rate(rathor_valence_spikes_total[5m])) * 60
